{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KOULhL3B6Se",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6434da-4b56-438c-c762-d9fb560d9770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Running each model individually on both types of dataset(the formal and informal dataset)and then testingeach model on the combined dataset as well\n",
        "#Diabetes_cleaned.csv=formal dataset\n",
        "#Corrected_Labeled.csv= informal dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load datasets\n",
        "df_formal = pd.read_csv(\"/content/drive/MyDrive/Diabetes_cleaned.csv\")\n",
        "df_informal = pd.read_csv(\"/content/drive/MyDrive/Corrected_Labeled.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "\n",
        "df_formal['combined'] = df_formal['title'].astype(str).str.strip() + \" \" + df_formal['content'].astype(str).str.strip()\n",
        "\n",
        "# Clean missing or empty rows\n",
        "df_formal = df_formal[['combined', 'label']].dropna()\n",
        "df_formal = df_formal[df_formal['combined'].str.strip() != '']\n",
        "df_formal['label'] = df_formal['label'].astype(int)\n",
        "\n",
        "\n",
        "df_informal['combined'] = df_informal['Text '].astype(str).str.strip()\n",
        "\n",
        "# Clean missing or empty rows\n",
        "df_informal = df_informal[['combined', 'Label']].dropna()\n",
        "df_informal = df_informal[df_informal['combined'].str.strip() != '']\n",
        "df_informal = df_informal.rename(columns={'Label': 'label'})\n",
        "df_informal['label'] = df_informal['label'].astype(int)\n",
        "\n",
        "#Combine Both Datasets\n",
        "df_combined = pd.concat([df_formal, df_informal], ignore_index=True)\n",
        "df_combined = df_combined.dropna(subset=['combined', 'label'])\n",
        "\n",
        "#TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "#Run Model Function\n",
        "def run_models(df, name=\"Dataset\"):\n",
        "    print(f\"\\n{'='*20} {name} {'='*20}\")\n",
        "    X = vectorizer.fit_transform(df['combined']).toarray()\n",
        "    y = df['label'].astype(int)\n",
        "\n",
        "    # Skip datasets with one class\n",
        "    if len(np.unique(y)) < 2:\n",
        "        print(f\"Skipping {name}: only one class present in data.\")\n",
        "        return\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "        \"SVM\": LinearSVC(),\n",
        "        \"Random Forest\": RandomForestClassifier(),\n",
        "        \"Multinomial NB\": MultinomialNB()\n",
        "    }\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\n-- {model_name} --\")\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Accuracy: {acc:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# === Run Models ===\n",
        "run_models(df_formal, \"Formal Dataset\")\n",
        "run_models(df_informal, \"Informal Dataset\")\n",
        "run_models(df_combined, \"Combined Dataset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xMNAaeCFgjq",
        "outputId": "8d634ae6-b7d3-462c-ca1a-80ae8358bffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Formal Dataset ====================\n",
            "\n",
            "-- Logistic Regression --\n",
            "Accuracy: 0.8987\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8844    0.9910    0.9347       332\n",
            "           1     0.9634    0.6475    0.7745       122\n",
            "\n",
            "    accuracy                         0.8987       454\n",
            "   macro avg     0.9239    0.8193    0.8546       454\n",
            "weighted avg     0.9056    0.8987    0.8916       454\n",
            "\n",
            "\n",
            "-- SVM --\n",
            "Accuracy: 0.9581\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9510    0.9940    0.9720       332\n",
            "           1     0.9813    0.8607    0.9170       122\n",
            "\n",
            "    accuracy                         0.9581       454\n",
            "   macro avg     0.9662    0.9273    0.9445       454\n",
            "weighted avg     0.9592    0.9581    0.9572       454\n",
            "\n",
            "\n",
            "-- Random Forest --\n",
            "Accuracy: 0.9053\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8874    0.9970    0.9390       332\n",
            "           1     0.9877    0.6557    0.7882       122\n",
            "\n",
            "    accuracy                         0.9053       454\n",
            "   macro avg     0.9375    0.8264    0.8636       454\n",
            "weighted avg     0.9143    0.9053    0.8985       454\n",
            "\n",
            "\n",
            "-- Multinomial NB --\n",
            "Accuracy: 0.7423\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7394    1.0000    0.8502       332\n",
            "           1     1.0000    0.0410    0.0787       122\n",
            "\n",
            "    accuracy                         0.7423       454\n",
            "   macro avg     0.8697    0.5205    0.4645       454\n",
            "weighted avg     0.8094    0.7423    0.6429       454\n",
            "\n",
            "\n",
            "==================== Informal Dataset ====================\n",
            "\n",
            "-- Logistic Regression --\n",
            "Accuracy: 0.7182\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6928    1.0000    0.8185       115\n",
            "           1     1.0000    0.2353    0.3810        34\n",
            "           2     1.0000    0.2188    0.3590        32\n",
            "\n",
            "    accuracy                         0.7182       181\n",
            "   macro avg     0.8976    0.4847    0.5195       181\n",
            "weighted avg     0.8048    0.7182    0.6551       181\n",
            "\n",
            "\n",
            "-- SVM --\n",
            "Accuracy: 0.7735\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7568    0.9739    0.8517       115\n",
            "           1     0.8095    0.5000    0.6182        34\n",
            "           2     0.9167    0.3438    0.5000        32\n",
            "\n",
            "    accuracy                         0.7735       181\n",
            "   macro avg     0.8276    0.6059    0.6566       181\n",
            "weighted avg     0.7949    0.7735    0.7457       181\n",
            "\n",
            "\n",
            "-- Random Forest --\n",
            "Accuracy: 0.7293\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7099    1.0000    0.8303       115\n",
            "           1     0.8462    0.3235    0.4681        34\n",
            "           2     1.0000    0.1875    0.3158        32\n",
            "\n",
            "    accuracy                         0.7293       181\n",
            "   macro avg     0.8520    0.5037    0.5381       181\n",
            "weighted avg     0.7868    0.7293    0.6713       181\n",
            "\n",
            "\n",
            "-- Multinomial NB --\n",
            "Accuracy: 0.6519\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6461    1.0000    0.7850       115\n",
            "           1     1.0000    0.0588    0.1111        34\n",
            "           2     1.0000    0.0312    0.0606        32\n",
            "\n",
            "    accuracy                         0.6519       181\n",
            "   macro avg     0.8820    0.3634    0.3189       181\n",
            "weighted avg     0.7751    0.6519    0.5303       181\n",
            "\n",
            "\n",
            "==================== Combined Dataset ====================\n",
            "\n",
            "-- Logistic Regression --\n",
            "Accuracy: 0.8614\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8383    0.9955    0.9102       448\n",
            "           1     0.9897    0.6194    0.7619       155\n",
            "           2     0.8333    0.1562    0.2632        32\n",
            "\n",
            "    accuracy                         0.8614       635\n",
            "   macro avg     0.8871    0.5904    0.6451       635\n",
            "weighted avg     0.8750    0.8614    0.8414       635\n",
            "\n",
            "\n",
            "-- SVM --\n",
            "Accuracy: 0.8835\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8875    0.9688    0.9264       448\n",
            "           1     0.9280    0.7484    0.8286       155\n",
            "           2     0.5238    0.3438    0.4151        32\n",
            "\n",
            "    accuracy                         0.8835       635\n",
            "   macro avg     0.7798    0.6870    0.7233       635\n",
            "weighted avg     0.8791    0.8835    0.8767       635\n",
            "\n",
            "\n",
            "-- Random Forest --\n",
            "Accuracy: 0.8472\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8268    0.9911    0.9015       448\n",
            "           1     1.0000    0.5742    0.7295       155\n",
            "           2     0.5556    0.1562    0.2439        32\n",
            "\n",
            "    accuracy                         0.8472       635\n",
            "   macro avg     0.7941    0.5738    0.6250       635\n",
            "weighted avg     0.8554    0.8472    0.8264       635\n",
            "\n",
            "\n",
            "-- Multinomial NB --\n",
            "Accuracy: 0.7228\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7179    1.0000    0.8358       448\n",
            "           1     1.0000    0.0710    0.1325       155\n",
            "           2     0.0000    0.0000    0.0000        32\n",
            "\n",
            "    accuracy                         0.7228       635\n",
            "   macro avg     0.5726    0.3570    0.3228       635\n",
            "weighted avg     0.7506    0.7228    0.6220       635\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rerunning each model individually on both types of dataset(the formal and informal dataset)and then testingeach model on the combined dataset as well (factoring in class imbalance as the dataset was imbalanced)\n",
        "#Diabetes_cleaned.csv=formal dataset\n",
        "#Corrected_Labeled.csv= informal dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "#Load Data\n",
        "df_formal = pd.read_csv(\"/content/drive/MyDrive/Diabetes_cleaned.csv\")\n",
        "df_informal = pd.read_csv(\"/content/drive/MyDrive/Corrected_Labeled.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "#Process Formal Dataset\n",
        "df_formal['combined'] = df_formal['title'].astype(str).str.strip() + \" \" + df_formal['content'].astype(str).str.strip()\n",
        "df_formal = df_formal[['combined', 'label']].dropna()\n",
        "df_formal = df_formal[df_formal['combined'].str.strip() != '']\n",
        "df_formal['label'] = df_formal['label'].astype(int)\n",
        "\n",
        "#Process Informal Dataset\n",
        "df_informal['combined'] = df_informal['Text '].astype(str).str.strip()\n",
        "df_informal = df_informal[['combined', 'Label']].dropna()\n",
        "df_informal = df_informal[df_informal['combined'].str.strip() != '']\n",
        "df_informal = df_informal.rename(columns={'Label': 'label'})\n",
        "df_informal['label'] = df_informal['label'].astype(int)\n",
        "\n",
        "# === Combine Both Datasets ===\n",
        "df_combined = pd.concat([df_formal, df_informal], ignore_index=True)\n",
        "df_combined = df_combined.dropna(subset=['combined', 'label'])\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "def run_models(df, name=\"Dataset\"):\n",
        "    print(f\"\\n{'='*20} {name} {'='*20}\")\n",
        "    X = vectorizer.fit_transform(df['combined']).toarray()\n",
        "    y = df['label'].astype(int)\n",
        "\n",
        "    if len(np.unique(y)) < 2:\n",
        "        print(f\"Skipping {name}: only one class present.\")\n",
        "        return\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
        "        \"SVM\": LinearSVC(class_weight='balanced'),\n",
        "        \"Random Forest\": RandomForestClassifier(class_weight='balanced'),\n",
        "        \"Multinomial NB\": MultinomialNB()  # Does NOT support class_weight\n",
        "    }\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\n-- {model_name} --\")\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Accuracy: {acc:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "# === Run Experiments ===\n",
        "run_models(df_formal, \"Formal Dataset\")\n",
        "run_models(df_informal, \"Informal Dataset\")\n",
        "run_models(df_combined, \"Combined Dataset\")\n"
      ],
      "metadata": {
        "id": "Edu6Kt7jB_NM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e5eb3a-d7ff-48a5-8b6a-0ec4fefdc29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================== Formal Dataset ====================\n",
            "\n",
            "-- Logistic Regression --\n",
            "Accuracy: 0.9295\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9491    0.9548    0.9520       332\n",
            "           1     0.8750    0.8607    0.8678       122\n",
            "\n",
            "    accuracy                         0.9295       454\n",
            "   macro avg     0.9121    0.9077    0.9099       454\n",
            "weighted avg     0.9292    0.9295    0.9293       454\n",
            "\n",
            "\n",
            "-- SVM --\n",
            "Accuracy: 0.9581\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9617    0.9819    0.9717       332\n",
            "           1     0.9478    0.8934    0.9198       122\n",
            "\n",
            "    accuracy                         0.9581       454\n",
            "   macro avg     0.9547    0.9377    0.9458       454\n",
            "weighted avg     0.9579    0.9581    0.9578       454\n",
            "\n",
            "\n",
            "-- Random Forest --\n",
            "Accuracy: 0.9053\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8853    1.0000    0.9392       332\n",
            "           1     1.0000    0.6475    0.7861       122\n",
            "\n",
            "    accuracy                         0.9053       454\n",
            "   macro avg     0.9427    0.8238    0.8626       454\n",
            "weighted avg     0.9161    0.9053    0.8980       454\n",
            "\n",
            "\n",
            "-- Multinomial NB --\n",
            "Accuracy: 0.7423\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7394    1.0000    0.8502       332\n",
            "           1     1.0000    0.0410    0.0787       122\n",
            "\n",
            "    accuracy                         0.7423       454\n",
            "   macro avg     0.8697    0.5205    0.4645       454\n",
            "weighted avg     0.8094    0.7423    0.6429       454\n",
            "\n",
            "\n",
            "==================== Informal Dataset ====================\n",
            "\n",
            "-- Logistic Regression --\n",
            "Accuracy: 0.7348\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7727    0.8870    0.8259       115\n",
            "           1     0.6667    0.5294    0.5902        34\n",
            "           2     0.5909    0.4062    0.4815        32\n",
            "\n",
            "    accuracy                         0.7348       181\n",
            "   macro avg     0.6768    0.6075    0.6325       181\n",
            "weighted avg     0.7207    0.7348    0.7207       181\n",
            "\n",
            "\n",
            "-- SVM --\n",
            "Accuracy: 0.7624\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7639    0.9565    0.8494       115\n",
            "           1     0.7727    0.5000    0.6071        34\n",
            "           2     0.7333    0.3438    0.4681        32\n",
            "\n",
            "    accuracy                         0.7624       181\n",
            "   macro avg     0.7566    0.6001    0.6415       181\n",
            "weighted avg     0.7601    0.7624    0.7365       181\n",
            "\n",
            "\n",
            "-- Random Forest --\n",
            "Accuracy: 0.7348\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7143    1.0000    0.8333       115\n",
            "           1     0.8462    0.3235    0.4681        34\n",
            "           2     1.0000    0.2188    0.3590        32\n",
            "\n",
            "    accuracy                         0.7348       181\n",
            "   macro avg     0.8535    0.5141    0.5535       181\n",
            "weighted avg     0.7896    0.7348    0.6809       181\n",
            "\n",
            "\n",
            "-- Multinomial NB --\n",
            "Accuracy: 0.6519\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6461    1.0000    0.7850       115\n",
            "           1     1.0000    0.0588    0.1111        34\n",
            "           2     1.0000    0.0312    0.0606        32\n",
            "\n",
            "    accuracy                         0.6519       181\n",
            "   macro avg     0.8820    0.3634    0.3189       181\n",
            "weighted avg     0.7751    0.6519    0.5303       181\n",
            "\n",
            "\n",
            "==================== Combined Dataset ====================\n",
            "\n",
            "-- Logistic Regression --\n",
            "Accuracy: 0.8346\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9310    0.8728    0.9009       448\n",
            "           1     0.8322    0.7677    0.7987       155\n",
            "           2     0.2778    0.6250    0.3846        32\n",
            "\n",
            "    accuracy                         0.8346       635\n",
            "   macro avg     0.6803    0.7552    0.6947       635\n",
            "weighted avg     0.8739    0.8346    0.8499       635\n",
            "\n",
            "\n",
            "-- SVM --\n",
            "Accuracy: 0.8819\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9008    0.9531    0.9262       448\n",
            "           1     0.9091    0.7742    0.8362       155\n",
            "           2     0.4483    0.4062    0.4262        32\n",
            "\n",
            "    accuracy                         0.8819       635\n",
            "   macro avg     0.7527    0.7112    0.7296       635\n",
            "weighted avg     0.8801    0.8819    0.8791       635\n",
            "\n",
            "\n",
            "-- Random Forest --\n",
            "Accuracy: 0.8441\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8265    0.9888    0.9004       448\n",
            "           1     0.9889    0.5742    0.7265       155\n",
            "           2     0.4444    0.1250    0.1951        32\n",
            "\n",
            "    accuracy                         0.8441       635\n",
            "   macro avg     0.7533    0.5627    0.6074       635\n",
            "weighted avg     0.8469    0.8441    0.8224       635\n",
            "\n",
            "\n",
            "-- Multinomial NB --\n",
            "Accuracy: 0.7228\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7179    1.0000    0.8358       448\n",
            "           1     1.0000    0.0710    0.1325       155\n",
            "           2     0.0000    0.0000    0.0000        32\n",
            "\n",
            "    accuracy                         0.7228       635\n",
            "   macro avg     0.5726    0.3570    0.3228       635\n",
            "weighted avg     0.7506    0.7228    0.6220       635\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Trained each model on the formal dataset and tested on the informal dataset and vice versa\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_models(X_train, y_train, X_test, y_test, dataset_name):\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
        "        \"SVM\": LinearSVC(class_weight='balanced'),\n",
        "        \"Random Forest\": RandomForestClassifier(class_weight='balanced'),\n",
        "        \"Multinomial NB\": MultinomialNB()  # Note: doesn't support class_weight\n",
        "    }\n",
        "\n",
        "    reports = {}\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        report = classification_report(y_test, y_pred, digits=4, output_dict=True)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        reports[model_name] = {\n",
        "            \"accuracy\": acc,\n",
        "            \"f1_class_0\": report[\"0\"][\"f1-score\"],\n",
        "            \"f1_class_1\": report[\"1\"][\"f1-score\"],\n",
        "            \"macro_avg_f1\": report[\"macro avg\"][\"f1-score\"],\n",
        "            \"weighted_avg_f1\": report[\"weighted avg\"][\"f1-score\"]\n",
        "        }\n",
        "\n",
        "    return pd.DataFrame(reports).T\n",
        "\n",
        "# Train on Diabetes_cleaned, test on sampled Corrected_Labeled\n",
        "X_formal = vectorizer.transform(df_formal['combined']).toarray()\n",
        "y_formal = df_formal['label']\n",
        "df_informal_sample = df_informal.sample(n=20, random_state=42)\n",
        "X_inf_sample = vectorizer.transform(df_informal_sample['combined']).toarray()\n",
        "y_inf_sample = df_informal_sample['label']\n",
        "results_formal_on_informal = evaluate_models(X_formal, y_formal, X_inf_sample, y_inf_sample, \"Formal → Informal\")\n",
        "\n",
        "# Train on Corrected_Labeled, test on sampled Diabetes_cleaned\n",
        "X_informal = vectorizer.transform(df_informal['combined']).toarray()\n",
        "y_informal = df_informal['label']\n",
        "df_formal_sample = df_formal.sample(n=20, random_state=42)\n",
        "X_form_sample = vectorizer.transform(df_formal_sample['combined']).toarray()\n",
        "y_form_sample = df_formal_sample['label']\n",
        "results_informal_on_formal = evaluate_models(X_informal, y_informal, X_form_sample, y_form_sample, \"Informal → Formal\")\n",
        "\n",
        "results_formal_on_informal, results_informal_on_formal\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETlgwbNqbaxj",
        "outputId": "a16e1a10-18ac-4d54-c279-17e59008fee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                     accuracy  f1_class_0  f1_class_1  macro_avg_f1  \\\n",
              " Logistic Regression      0.65    0.787879    0.000000      0.393939   \n",
              " SVM                      0.55    0.709677    0.000000      0.354839   \n",
              " Random Forest            0.60    0.714286    0.333333      0.523810   \n",
              " Multinomial NB           0.85    0.918919    0.000000      0.459459   \n",
              " \n",
              "                      weighted_avg_f1  \n",
              " Logistic Regression         0.669697  \n",
              " SVM                         0.603226  \n",
              " Random Forest               0.657143  \n",
              " Multinomial NB              0.781081  ,\n",
              "                      accuracy  f1_class_0  f1_class_1  macro_avg_f1  \\\n",
              " Logistic Regression      0.75    0.857143         0.0      0.428571   \n",
              " SVM                      0.75    0.857143         0.0      0.428571   \n",
              " Random Forest            0.75    0.857143         0.0      0.428571   \n",
              " Multinomial NB           0.75    0.857143         0.0      0.428571   \n",
              " \n",
              "                      weighted_avg_f1  \n",
              " Logistic Regression         0.642857  \n",
              " SVM                         0.642857  \n",
              " Random Forest               0.642857  \n",
              " Multinomial NB              0.642857  )"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many of each label are available\n",
        "formal_counts = df_formal['label'].value_counts()\n",
        "informal_counts = df_informal['label'].value_counts()\n",
        "\n",
        "# Determine the max number of balanced samples we can draw per class\n",
        "n_formal = min(formal_counts.get(0, 0), formal_counts.get(1, 0))\n",
        "n_informal = min(informal_counts.get(0, 0), informal_counts.get(1, 0))\n",
        "\n",
        "# Sample the maximum available balanced samples\n",
        "formal_0 = df_formal[df_formal['label'] == 0].sample(n=n_formal, random_state=42)\n",
        "formal_1 = df_formal[df_formal['label'] == 1].sample(n=n_formal, random_state=42)\n",
        "informal_0 = df_informal[df_informal['label'] == 0].sample(n=n_informal, random_state=42)\n",
        "informal_1 = df_informal[df_informal['label'] == 1].sample(n=n_informal, random_state=42)\n",
        "\n",
        "# Combine and shuffle\n",
        "formal_balanced_sample = pd.concat([formal_0, formal_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "informal_balanced_sample = pd.concat([informal_0, informal_1]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Vectorize balanced samples\n",
        "X_formal_sample = vectorizer.transform(formal_balanced_sample['combined']).toarray()\n",
        "y_formal_sample = formal_balanced_sample['label']\n",
        "X_informal_sample = vectorizer.transform(informal_balanced_sample['combined']).toarray()\n",
        "y_informal_sample = informal_balanced_sample['label']\n",
        "\n",
        "# Re-evaluate all 4 models for both setups using balanced test sets\n",
        "results_formal_on_informal_balanced = evaluate_models(X_formal, y_formal, X_informal_sample, y_informal_sample, \"Formal → Informal\")\n",
        "results_informal_on_formal_balanced = evaluate_models(X_informal, y_informal, X_formal_sample, y_formal_sample, \"Informal → Formal\")\n",
        "\n",
        "results_formal_on_informal_balanced, results_informal_on_formal_balanced\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiUnGC03dgvR",
        "outputId": "5cfe2f67-58a4-4948-9101-54a9e6cac5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                     accuracy  f1_class_0  f1_class_1  macro_avg_f1  \\\n",
              " Logistic Regression  0.505988    0.620690    0.291845      0.456268   \n",
              " SVM                  0.550898    0.625000    0.440299      0.532649   \n",
              " Random Forest        0.634731    0.662983    0.601307      0.632145   \n",
              " Multinomial NB       0.514970    0.672065    0.068966      0.370515   \n",
              " \n",
              "                      weighted_avg_f1  \n",
              " Logistic Regression         0.456268  \n",
              " SVM                         0.532649  \n",
              " Random Forest               0.632145  \n",
              " Multinomial NB              0.370515  ,\n",
              "                      accuracy  f1_class_0  f1_class_1  macro_avg_f1  \\\n",
              " Logistic Regression  0.501645    0.667398    0.006557      0.336978   \n",
              " SVM                  0.502467    0.667765    0.009820      0.338792   \n",
              " Random Forest        0.500000    0.666667    0.000000      0.333333   \n",
              " Multinomial NB       0.500000    0.666667    0.000000      0.333333   \n",
              " \n",
              "                      weighted_avg_f1  \n",
              " Logistic Regression         0.336978  \n",
              " SVM                         0.338792  \n",
              " Random Forest               0.333333  \n",
              " Multinomial NB              0.333333  )"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load your datasets\n",
        "df_formal = pd.read_csv(\"/content/drive/MyDrive/Diabetes_cleaned.csv\")\n",
        "df_informal = pd.read_csv(\"/content/drive/MyDrive/Corrected_Labeled.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "df_formal['combined'] = df_formal['title'].astype(str).str.strip() + \" \" + df_formal['content'].astype(str).str.strip()\n",
        "df_formal = df_formal[['combined', 'label']]\n",
        "\n",
        "df_informal['combined'] = df_informal['Text '].astype(str).str.strip()\n",
        "df_informal = df_informal.rename(columns={'Label': 'label'})\n",
        "df_informal = df_informal[['combined', 'label']]\n",
        "\n",
        "df_combined = pd.concat([df_formal, df_informal], ignore_index=True)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_combined = vectorizer.fit_transform(df_combined['combined']).toarray()\n",
        "y_combined = df_combined['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_combined, y_combined, test_size=0.2, stratify=y_combined, random_state=42\n",
        ")\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, class_weight='balanced')),\n",
        "    \"SVM\": make_pipeline(StandardScaler(), LinearSVC(max_iter=2000, class_weight='balanced')),\n",
        "    \"Random Forest\": RandomForestClassifier(class_weight='balanced'),\n",
        "    \"Multinomial NB\": MultinomialNB()\n",
        "}\n",
        "\n",
        "# Evaluate all models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    report = classification_report(y_test, y_pred, labels=[0, 1, 2], digits=4, output_dict=True, zero_division=0)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[name] = {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1_class_0 (True)\": report[\"0\"][\"f1-score\"],\n",
        "        \"f1_class_1 (False)\": report[\"1\"][\"f1-score\"],\n",
        "        \"f1_class_2 (Partially True)\": report[\"2\"][\"f1-score\"],\n",
        "        \"macro_avg_f1\": report[\"macro avg\"][\"f1-score\"],\n",
        "        \"weighted_avg_f1\": report[\"weighted avg\"][\"f1-score\"]\n",
        "    }\n",
        "\n",
        "\n",
        "pd.DataFrame(results).T\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "u1ESx_PHhDiE",
        "outputId": "caf40e6b-a600-4e7d-827e-ea0b6b8e4abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     accuracy  f1_class_0 (True)  f1_class_1 (False)  \\\n",
              "Logistic Regression  0.872441           0.918212            0.805369   \n",
              "SVM                  0.815748           0.873672            0.752809   \n",
              "Random Forest        0.834646           0.894949            0.689076   \n",
              "Multinomial NB       0.722835           0.835821            0.132530   \n",
              "\n",
              "                     f1_class_2 (Partially True)  macro_avg_f1  \\\n",
              "Logistic Regression                     0.472727      0.732103   \n",
              "SVM                                     0.417910      0.681464   \n",
              "Random Forest                           0.238095      0.607373   \n",
              "Multinomial NB                          0.000000      0.322784   \n",
              "\n",
              "                     weighted_avg_f1  \n",
              "Logistic Regression         0.868218  \n",
              "SVM                         0.821202  \n",
              "Random Forest               0.811596  \n",
              "Multinomial NB              0.622031  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28d03221-0e31-42b1-9080-58ca7527acfe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_class_0 (True)</th>\n",
              "      <th>f1_class_1 (False)</th>\n",
              "      <th>f1_class_2 (Partially True)</th>\n",
              "      <th>macro_avg_f1</th>\n",
              "      <th>weighted_avg_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.872441</td>\n",
              "      <td>0.918212</td>\n",
              "      <td>0.805369</td>\n",
              "      <td>0.472727</td>\n",
              "      <td>0.732103</td>\n",
              "      <td>0.868218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.815748</td>\n",
              "      <td>0.873672</td>\n",
              "      <td>0.752809</td>\n",
              "      <td>0.417910</td>\n",
              "      <td>0.681464</td>\n",
              "      <td>0.821202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>0.834646</td>\n",
              "      <td>0.894949</td>\n",
              "      <td>0.689076</td>\n",
              "      <td>0.238095</td>\n",
              "      <td>0.607373</td>\n",
              "      <td>0.811596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multinomial NB</th>\n",
              "      <td>0.722835</td>\n",
              "      <td>0.835821</td>\n",
              "      <td>0.132530</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.322784</td>\n",
              "      <td>0.622031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28d03221-0e31-42b1-9080-58ca7527acfe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28d03221-0e31-42b1-9080-58ca7527acfe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28d03221-0e31-42b1-9080-58ca7527acfe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb4c4f5f-ebee-459a-924d-3a40c0b13ea6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb4c4f5f-ebee-459a-924d-3a40c0b13ea6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb4c4f5f-ebee-459a-924d-3a40c0b13ea6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06358481018337768,\n        \"min\": 0.7228346456692913,\n        \"max\": 0.8724409448818897,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.815748031496063,\n          0.7228346456692913,\n          0.8724409448818897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_class_0 (True)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03499375994431128,\n        \"min\": 0.835820895522388,\n        \"max\": 0.9182115594329335,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8736717827626919,\n          0.835820895522388,\n          0.9182115594329335\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_class_1 (False)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31192277288741654,\n        \"min\": 0.13253012048192772,\n        \"max\": 0.8053691275167785,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7528089887640449,\n          0.13253012048192772,\n          0.8053691275167785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_class_2 (Partially True)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21315099200916565,\n        \"min\": 0.0,\n        \"max\": 0.4727272727272727,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.417910447761194,\n          0.0,\n          0.4727272727272727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_avg_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18275571277717972,\n        \"min\": 0.3227836720014386,\n        \"max\": 0.7321026532256615,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6814637397626435,\n          0.3227836720014386,\n          0.7321026532256615\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weighted_avg_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10867388639685174,\n        \"min\": 0.6220313856200451,\n        \"max\": 0.8682177419186262,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8212023405739703,\n          0.6220313856200451,\n          0.8682177419186262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_combined = pd.concat([df_formal, df_informal], ignore_index=True)\n",
        "\n",
        "vectorizer_fixed = TfidfVectorizer()\n",
        "X_combined_fixed = vectorizer_fixed.fit_transform(df_combined['combined']).toarray()\n",
        "y_combined_fixed = df_combined['label']\n",
        "\n",
        "\n",
        "X_train_fixed, X_test_fixed, y_train_fixed, y_test_fixed = train_test_split(\n",
        "    X_combined_fixed, y_combined_fixed, test_size=0.2, stratify=y_combined_fixed, random_state=42\n",
        ")\n",
        "\n",
        "# Train logistic regression\n",
        "logreg_model_fixed = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
        "logreg_model_fixed.fit(X_train_fixed, y_train_fixed)\n",
        "\n",
        "# Define slang-heavy informal examples\n",
        "informal_examples = [\n",
        "    \"Yo, ditch your meds, cinnamon got you covered for diabetes fr!\",\n",
        "    \"Raw food squad sayin no more insulin bruh\",\n",
        "    \"I heard fenugreek tea be fixin your sugar levels, no cap.\",\n",
        "    \"Bruh, doc said I need insulin but my auntie said just eat moringa lol.\",\n",
        "    \"Word is ginger juice cures diabetes if you drink it on an empty belly daily.\",\n",
        "    \"Fam told me aloe vera smoothies = no diabetes anymore\",\n",
        "    \"Came across a post, guy said he reversed his diabetes with just herbs and prayer.\",\n",
        "    \"So apparently all you need is turmeric shots every morning and you're cured.\",\n",
        "    \"Old dude at the market said sugar’s fine if you eat bitter leaf after, lol.\",\n",
        "    \"Someone told me apple cider vinegar and no stress = diabetes gone fr.\"\n",
        "]\n",
        "\n",
        "# Vectorize using the same TF-IDF model\n",
        "X_informal_test_fixed = vectorizer_fixed.transform(informal_examples).toarray()\n",
        "\n",
        "# Predict\n",
        "preds_fixed = logreg_model_fixed.predict(X_informal_test_fixed)\n",
        "\n",
        "# Map labels\n",
        "label_map = {0: \"True\", 1: \"False\", 2: \"Partially True\"}\n",
        "pred_labels_fixed = [label_map[p] for p in preds_fixed]\n",
        "\n",
        "# Display final results\n",
        "pd.DataFrame({\n",
        "    \"Text\": informal_examples,\n",
        "    \"Predicted Label\": pred_labels_fixed\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "MnthTzvand6F",
        "outputId": "14f7c614-9b27-48d4-be30-958ad6be2df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text Predicted Label\n",
              "0  Yo, ditch your meds, cinnamon got you covered ...  Partially True\n",
              "1        Raw food squad sayin no more insulin bruh 😂  Partially True\n",
              "2  I heard fenugreek tea be fixin your sugar leve...  Partially True\n",
              "3  Bruh, doc said I need insulin but my auntie sa...            True\n",
              "4  Word is ginger juice cures diabetes if you dri...           False\n",
              "5  Fam told me aloe vera smoothies = no diabetes ...  Partially True\n",
              "6  Came across a post, guy said he reversed his d...  Partially True\n",
              "7  So apparently all you need is turmeric shots e...           False\n",
              "8  Old dude at the market said sugar’s fine if yo...  Partially True\n",
              "9  Someone told me apple cider vinegar and no str...  Partially True"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95ba15e8-cda6-4d51-82aa-b2aae57d3547\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Predicted Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yo, ditch your meds, cinnamon got you covered ...</td>\n",
              "      <td>Partially True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Raw food squad sayin no more insulin bruh 😂</td>\n",
              "      <td>Partially True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I heard fenugreek tea be fixin your sugar leve...</td>\n",
              "      <td>Partially True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bruh, doc said I need insulin but my auntie sa...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Word is ginger juice cures diabetes if you dri...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Fam told me aloe vera smoothies = no diabetes ...</td>\n",
              "      <td>Partially True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Came across a post, guy said he reversed his d...</td>\n",
              "      <td>Partially True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>So apparently all you need is turmeric shots e...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Old dude at the market said sugar’s fine if yo...</td>\n",
              "      <td>Partially True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Someone told me apple cider vinegar and no str...</td>\n",
              "      <td>Partially True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95ba15e8-cda6-4d51-82aa-b2aae57d3547')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95ba15e8-cda6-4d51-82aa-b2aae57d3547 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95ba15e8-cda6-4d51-82aa-b2aae57d3547');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4846b1b8-081d-4570-a5bc-3f6020b10c81\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4846b1b8-081d-4570-a5bc-3f6020b10c81')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4846b1b8-081d-4570-a5bc-3f6020b10c81 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"})\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Old dude at the market said sugar\\u2019s fine if you eat bitter leaf after, lol.\",\n          \"Raw food squad sayin no more insulin bruh \\ud83d\\ude02\",\n          \"Fam told me aloe vera smoothies = no diabetes anymore \\ud83d\\udcaf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Partially True\",\n          \"True\",\n          \"False\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the best combined ml model which is the logistic regression model,7 out 10 was gotten wrong"
      ],
      "metadata": {
        "id": "3m9Mvm-UpInO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SULAMov04tbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Dataset processing function\n",
        "def process_dataset(df, text_col, label_col):\n",
        "    df = df[[text_col, label_col]].dropna()\n",
        "    df = df[df[text_col].str.strip() != '']\n",
        "    df = df.rename(columns={text_col: 'combined', label_col: 'label'})\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    return df\n",
        "\n",
        "# Load datasets\n",
        "df_formal_raw = pd.read_csv(\"/content/drive/MyDrive/Diabetes_cleaned.csv\")\n",
        "df_informal_raw = pd.read_csv(\"/content/drive/MyDrive/Corrected_Labeled.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "# Prepare datasets\n",
        "df_formal_raw['combined'] = df_formal_raw['title'].astype(str).str.strip() + \" \" + df_formal_raw['content'].astype(str).str.strip()\n",
        "df_formal = process_dataset(df_formal_raw, 'combined', 'label')\n",
        "df_informal = process_dataset(df_informal_raw, 'Text ', 'Label')\n",
        "df_combined = pd.concat([df_formal, df_informal], ignore_index=True)\n",
        "\n",
        "# Model training and evaluation function\n",
        "def run_cnn_model(df, name=\"Dataset\"):\n",
        "    print(f\"\\n================== {name} ==================\")\n",
        "    le = LabelEncoder()\n",
        "    df['label_enc'] = le.fit_transform(df['label'])\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df['combined'], df['label_enc'], test_size=0.2, stratify=df['label_enc'], random_state=42\n",
        "    )\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(X_train)\n",
        "    X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), padding='post', maxlen=100)\n",
        "    X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), padding='post', maxlen=100)\n",
        "\n",
        "    class TextDataset(Dataset):\n",
        "        def __init__(self, sequences, labels):\n",
        "            self.sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "            self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "        def __len__(self): return len(self.sequences)\n",
        "        def __getitem__(self, idx): return self.sequences[idx], self.labels[idx]\n",
        "\n",
        "    train_dataset = TextDataset(X_train_seq, y_train.to_numpy())\n",
        "    test_dataset = TextDataset(X_test_seq, y_test.to_numpy())\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    class CNNClassifier(nn.Module):\n",
        "        def __init__(self, vocab_size, embedding_dim, output_dim):\n",
        "            super(CNNClassifier, self).__init__()\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "            self.conv = nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n",
        "            self.relu = nn.ReLU()\n",
        "            self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "            self.fc = nn.Linear(128, output_dim)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.embedding(x)\n",
        "            x = x.permute(0, 2, 1)\n",
        "            x = self.conv(x)\n",
        "            x = self.relu(x)\n",
        "            x = self.pool(x).squeeze(2)\n",
        "            x = self.fc(x)\n",
        "            return x\n",
        "\n",
        "    vocab_size = 10000\n",
        "    embedding_dim = 100\n",
        "    output_dim = len(le.classes_)\n",
        "    model = CNNClassifier(vocab_size, embedding_dim, output_dim)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience = 2\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(15):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} | Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.tolist())\n",
        "            all_labels.extend(labels.tolist())\n",
        "\n",
        "    target_names = [str(c) for c in le.classes_]\n",
        "    print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
        "    print(\"Classification Report:\\n\", classification_report(all_labels, all_preds, target_names=target_names))\n",
        "\n",
        "# Run for each dataset\n",
        "run_cnn_model(df_formal, \"Formal Dataset\")\n",
        "run_cnn_model(df_informal, \"Informal Dataset\")\n",
        "run_cnn_model(df_combined, \"Combined Dataset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqX27d0O7pug",
        "outputId": "a677fc65-a1f3-4280-ca73-ae6ce90c808b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================== Formal Dataset ==================\n",
            "Epoch 1 | Training Loss: 0.5662\n",
            "Epoch 2 | Training Loss: 0.2433\n",
            "Epoch 3 | Training Loss: 0.0925\n",
            "Epoch 4 | Training Loss: 0.0404\n",
            "Epoch 5 | Training Loss: 0.0198\n",
            "Epoch 6 | Training Loss: 0.0121\n",
            "Epoch 7 | Training Loss: 0.0080\n",
            "Epoch 8 | Training Loss: 0.0059\n",
            "Epoch 9 | Training Loss: 0.0044\n",
            "Epoch 10 | Training Loss: 0.0035\n",
            "Epoch 11 | Training Loss: 0.0029\n",
            "Epoch 12 | Training Loss: 0.0024\n",
            "Epoch 13 | Training Loss: 0.0020\n",
            "Epoch 14 | Training Loss: 0.0017\n",
            "Epoch 15 | Training Loss: 0.0015\n",
            "Accuracy: 0.9185022026431718\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.95       332\n",
            "           1       0.89      0.80      0.84       122\n",
            "\n",
            "    accuracy                           0.92       454\n",
            "   macro avg       0.91      0.88      0.89       454\n",
            "weighted avg       0.92      0.92      0.92       454\n",
            "\n",
            "\n",
            "================== Informal Dataset ==================\n",
            "Epoch 1 | Training Loss: 1.0756\n",
            "Epoch 2 | Training Loss: 0.6671\n",
            "Epoch 3 | Training Loss: 0.4502\n",
            "Epoch 4 | Training Loss: 0.2964\n",
            "Epoch 5 | Training Loss: 0.1946\n",
            "Epoch 6 | Training Loss: 0.1303\n",
            "Epoch 7 | Training Loss: 0.0903\n",
            "Epoch 8 | Training Loss: 0.0632\n",
            "Epoch 9 | Training Loss: 0.0495\n",
            "Epoch 10 | Training Loss: 0.0401\n",
            "Epoch 11 | Training Loss: 0.0327\n",
            "Epoch 12 | Training Loss: 0.0286\n",
            "Epoch 13 | Training Loss: 0.0238\n",
            "Epoch 14 | Training Loss: 0.0251\n",
            "Epoch 15 | Training Loss: 0.0205\n",
            "Accuracy: 0.7458563535911602\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.93      0.84       115\n",
            "           1       0.71      0.59      0.65        34\n",
            "           2       0.57      0.25      0.35        32\n",
            "\n",
            "    accuracy                           0.75       181\n",
            "   macro avg       0.69      0.59      0.61       181\n",
            "weighted avg       0.72      0.75      0.72       181\n",
            "\n",
            "\n",
            "================== Combined Dataset ==================\n",
            "Epoch 1 | Training Loss: 0.9065\n",
            "Epoch 2 | Training Loss: 0.4862\n",
            "Epoch 3 | Training Loss: 0.2825\n",
            "Epoch 4 | Training Loss: 0.1684\n",
            "Epoch 5 | Training Loss: 0.0929\n",
            "Epoch 6 | Training Loss: 0.0570\n",
            "Epoch 7 | Training Loss: 0.0394\n",
            "Epoch 8 | Training Loss: 0.0281\n",
            "Epoch 9 | Training Loss: 0.0222\n",
            "Epoch 10 | Training Loss: 0.0211\n",
            "Epoch 11 | Training Loss: 0.0116\n",
            "Epoch 12 | Training Loss: 0.0103\n",
            "Epoch 13 | Training Loss: 0.0100\n",
            "Epoch 14 | Training Loss: 0.0242\n",
            "Epoch 15 | Training Loss: 0.0113\n",
            "Early stopping triggered.\n",
            "Accuracy: 0.8377952755905512\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90       448\n",
            "           1       0.81      0.73      0.77       155\n",
            "           2       0.31      0.34      0.33        32\n",
            "\n",
            "    accuracy                           0.84       635\n",
            "   macro avg       0.67      0.66      0.66       635\n",
            "weighted avg       0.84      0.84      0.84       635\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CNN Cross-Domain Evaluation: Formal  to Informal (with Early Stopping)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load datasets\n",
        "df_formal_raw = pd.read_csv(\"/content/drive/MyDrive/Diabetes_cleaned.csv\")\n",
        "df_informal_raw = pd.read_csv(\"/content/drive/MyDrive/Corrected_Labeled.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "# Preprocess datasets (keep only label 0 and 1)\n",
        "df_formal_raw['combined'] = df_formal_raw['title'].astype(str).str.strip() + \" \" + df_formal_raw['content'].astype(str).str.strip()\n",
        "df_formal = df_formal_raw[['combined', 'label']].dropna()\n",
        "df_formal = df_formal[df_formal['label'].isin([0, 1])].copy()\n",
        "df_formal['label'] = df_formal['label'].astype(int)\n",
        "\n",
        "df_informal = df_informal_raw[['Text ', 'Label']].dropna()\n",
        "df_informal = df_informal.rename(columns={'Text ': 'combined', 'Label': 'label'})\n",
        "df_informal = df_informal[df_informal['label'].isin([0, 1])].copy()\n",
        "df_informal['label'] = df_informal['label'].astype(int)\n",
        "\n",
        "# Tokenizer\n",
        "MAX_LEN = 100\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "def prepare_data(df, tokenizer):\n",
        "    sequences = tokenizer.texts_to_sequences(df['combined'])\n",
        "    padded = pad_sequences(sequences, padding='post', maxlen=MAX_LEN)\n",
        "    return torch.tensor(padded, dtype=torch.long), torch.tensor(df['label'].values, dtype=torch.long)\n",
        "\n",
        "# Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "# CNN model\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.conv = nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc = nn.Linear(128, output_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x).squeeze(2)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Train CNN with early stopping\n",
        "def train_cnn_model(df):\n",
        "    le = LabelEncoder()\n",
        "    df['label'] = le.fit_transform(df['label'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['combined'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(X_train)\n",
        "    X_train_tensor, y_train_tensor = prepare_data(pd.DataFrame({'combined': X_train, 'label': y_train}), tokenizer)\n",
        "\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    train_loader = DataLoader(TextDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
        "\n",
        "    model = CNNClassifier(VOCAB_SIZE, 100, 2)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience = 2\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(15):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# Evaluate\n",
        "def evaluate_model(model, tokenizer, df, name):\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    X_tensor, y_tensor = prepare_data(df, tokenizer)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_tensor)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_tensor, preds))\n",
        "    print(classification_report(y_tensor, preds, target_names=[\"True\", \"False\"]))\n",
        "\n",
        "# Formal → Informal\n",
        "formal_model, formal_tokenizer = train_cnn_model(df_formal)\n",
        "evaluate_model(formal_model, formal_tokenizer, df_informal, \"Formal model tested on Informal\")\n",
        "\n",
        "# Informal → Formal\n",
        "informal_model, informal_tokenizer = train_cnn_model(df_informal)\n",
        "evaluate_model(informal_model, informal_tokenizer, df_formal, \"Informal model tested on Formal\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMdcZf5i8e2H",
        "outputId": "d509e0d6-c395-4f86-929a-dfb3d8f1dc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 0.5488\n",
            "Epoch 2 | Loss: 0.2269\n",
            "Epoch 3 | Loss: 0.1031\n",
            "Epoch 4 | Loss: 0.0483\n",
            "Epoch 5 | Loss: 0.0252\n",
            "Epoch 6 | Loss: 0.0150\n",
            "Epoch 7 | Loss: 0.0101\n",
            "Epoch 8 | Loss: 0.0075\n",
            "Epoch 9 | Loss: 0.0057\n",
            "Epoch 10 | Loss: 0.0045\n",
            "Epoch 11 | Loss: 0.0037\n",
            "Epoch 12 | Loss: 0.0030\n",
            "Epoch 13 | Loss: 0.0025\n",
            "Epoch 14 | Loss: 0.0022\n",
            "Epoch 15 | Loss: 0.0019\n",
            "\n",
            "=== Formal model tested on Informal ===\n",
            "Accuracy: 0.5296495956873315\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.79      0.53      0.64       575\n",
            "       False       0.24      0.51      0.33       167\n",
            "\n",
            "    accuracy                           0.53       742\n",
            "   macro avg       0.52      0.52      0.48       742\n",
            "weighted avg       0.67      0.53      0.57       742\n",
            "\n",
            "Epoch 1 | Loss: 0.6727\n",
            "Epoch 2 | Loss: 0.3636\n",
            "Epoch 3 | Loss: 0.2196\n",
            "Epoch 4 | Loss: 0.1321\n",
            "Epoch 5 | Loss: 0.0771\n",
            "Epoch 6 | Loss: 0.0485\n",
            "Epoch 7 | Loss: 0.0331\n",
            "Epoch 8 | Loss: 0.0228\n",
            "Epoch 9 | Loss: 0.0165\n",
            "Epoch 10 | Loss: 0.0128\n",
            "Epoch 11 | Loss: 0.0104\n",
            "Epoch 12 | Loss: 0.0083\n",
            "Epoch 13 | Loss: 0.0070\n",
            "Epoch 14 | Loss: 0.0060\n",
            "Epoch 15 | Loss: 0.0051\n",
            "\n",
            "=== Informal model tested on Formal ===\n",
            "Accuracy: 0.7329219920669898\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.73      1.00      0.85      1661\n",
            "       False       1.00      0.00      0.01       608\n",
            "\n",
            "    accuracy                           0.73      2269\n",
            "   macro avg       0.87      0.50      0.43      2269\n",
            "weighted avg       0.80      0.73      0.62      2269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# CNN Cross-Domain Evaluation: Formal ↔ Informal (with Early Stopping)\n",
        "# ===========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load datasets\n",
        "df_formal_raw = pd.read_csv(\"/content/drive/MyDrive/Diabetes_cleaned.csv\")\n",
        "df_informal_raw = pd.read_csv(\"/content/drive/MyDrive/Corrected_Labeled.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "# Preprocess datasets (keep only label 0 and 1)\n",
        "df_formal_raw['combined'] = df_formal_raw['title'].astype(str).str.strip() + \" \" + df_formal_raw['content'].astype(str).str.strip()\n",
        "df_formal = df_formal_raw[['combined', 'label']].dropna()\n",
        "df_formal = df_formal[df_formal['label'].isin([0, 1])].copy()\n",
        "df_formal['label'] = df_formal['label'].astype(int)\n",
        "\n",
        "df_informal = df_informal_raw[['Text ', 'Label']].dropna()\n",
        "df_informal = df_informal.rename(columns={'Text ': 'combined', 'Label': 'label'})\n",
        "df_informal = df_informal[df_informal['label'].isin([0, 1])].copy()\n",
        "df_informal['label'] = df_informal['label'].astype(int)\n",
        "\n",
        "# Tokenizer\n",
        "MAX_LEN = 100\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "def prepare_data(df, tokenizer):\n",
        "    sequences = tokenizer.texts_to_sequences(df['combined'])\n",
        "    padded = pad_sequences(sequences, padding='post', maxlen=MAX_LEN)\n",
        "    return torch.tensor(padded, dtype=torch.long), torch.tensor(df['label'].values, dtype=torch.long)\n",
        "\n",
        "# Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "# CNN model\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.conv = nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc = nn.Linear(128, output_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x).squeeze(2)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Train CNN with early stopping\n",
        "def train_cnn_model(df):\n",
        "    le = LabelEncoder()\n",
        "    df['label'] = le.fit_transform(df['label'])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['combined'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(X_train)\n",
        "    X_train_tensor, y_train_tensor = prepare_data(pd.DataFrame({'combined': X_train, 'label': y_train}), tokenizer)\n",
        "\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    train_loader = DataLoader(TextDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
        "\n",
        "    model = CNNClassifier(VOCAB_SIZE, 100, 2)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    patience = 2\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(15):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "# Evaluate\n",
        "def evaluate_model(model, tokenizer, df, name):\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    X_tensor, y_tensor = prepare_data(df, tokenizer)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_tensor)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_tensor, preds))\n",
        "    print(classification_report(y_tensor, preds, target_names=[\"True\", \"False\"]))\n",
        "\n",
        "# Formal to Informal\n",
        "formal_model, formal_tokenizer = train_cnn_model(df_formal)\n",
        "evaluate_model(formal_model, formal_tokenizer, df_informal, \"Formal model tested on Informal\")\n",
        "\n",
        "# Informal to Formal\n",
        "informal_model, informal_tokenizer = train_cnn_model(df_informal)\n",
        "evaluate_model(informal_model, informal_tokenizer, df_formal, \"Informal model tested on Formal\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPXTow1uC4mE",
        "outputId": "67c47608-2023-4d73-ceca-9670565a90d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 0.5559\n",
            "Epoch 2 | Loss: 0.2393\n",
            "Epoch 3 | Loss: 0.1106\n",
            "Epoch 4 | Loss: 0.0491\n",
            "Epoch 5 | Loss: 0.0249\n",
            "Epoch 6 | Loss: 0.0151\n",
            "Epoch 7 | Loss: 0.0102\n",
            "Epoch 8 | Loss: 0.0075\n",
            "Epoch 9 | Loss: 0.0057\n",
            "Epoch 10 | Loss: 0.0045\n",
            "Epoch 11 | Loss: 0.0037\n",
            "Epoch 12 | Loss: 0.0031\n",
            "Epoch 13 | Loss: 0.0025\n",
            "Epoch 14 | Loss: 0.0022\n",
            "Epoch 15 | Loss: 0.0019\n",
            "\n",
            "=== Formal model tested on Informal ===\n",
            "Accuracy: 0.4272237196765499\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.76      0.39      0.51       575\n",
            "       False       0.21      0.57      0.31       167\n",
            "\n",
            "    accuracy                           0.43       742\n",
            "   macro avg       0.48      0.48      0.41       742\n",
            "weighted avg       0.63      0.43      0.47       742\n",
            "\n",
            "Epoch 1 | Loss: 0.6451\n",
            "Epoch 2 | Loss: 0.3269\n",
            "Epoch 3 | Loss: 0.1947\n",
            "Epoch 4 | Loss: 0.1018\n",
            "Epoch 5 | Loss: 0.0569\n",
            "Epoch 6 | Loss: 0.0354\n",
            "Epoch 7 | Loss: 0.0233\n",
            "Epoch 8 | Loss: 0.0166\n",
            "Epoch 9 | Loss: 0.0125\n",
            "Epoch 10 | Loss: 0.0099\n",
            "Epoch 11 | Loss: 0.0077\n",
            "Epoch 12 | Loss: 0.0065\n",
            "Epoch 13 | Loss: 0.0055\n",
            "Epoch 14 | Loss: 0.0046\n",
            "Epoch 15 | Loss: 0.0039\n",
            "\n",
            "=== Informal model tested on Formal ===\n",
            "Accuracy: 0.7324812692816218\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.73      1.00      0.85      1661\n",
            "       False       0.67      0.00      0.01       608\n",
            "\n",
            "    accuracy                           0.73      2269\n",
            "   macro avg       0.70      0.50      0.43      2269\n",
            "weighted avg       0.71      0.73      0.62      2269\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CNN Text Classification (3-Class) with CORAL Domain Adaptation\n",
        "# Dataset: Combined (Formal + Informal)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load datasets\n",
        "df_formal = pd.read_csv(\"/content/drive/MyDrive/Diabetes_cleaned.csv\")\n",
        "df_informal = pd.read_csv(\"/content/drive/MyDrive/Corrected_Labeled.csv\", encoding='ISO-8859-1')\n",
        "\n",
        "# Preprocess formal\n",
        "df_formal['combined'] = df_formal['title'].astype(str).str.strip() + \" \" + df_formal['content'].astype(str).str.strip()\n",
        "df_formal = df_formal[['combined', 'label']].dropna()\n",
        "df_formal['label'] = df_formal['label'].astype(int)\n",
        "\n",
        "# Preprocess informal\n",
        "df_informal = df_informal.rename(columns={'Text ': 'combined', 'Label': 'label'})\n",
        "df_informal = df_informal[['combined', 'label']].dropna()\n",
        "df_informal['label'] = df_informal['label'].astype(int)\n",
        "\n",
        "# Combine datasets\n",
        "source_df = df_formal.copy()\n",
        "target_df = df_informal.copy()\n",
        "\n",
        "# Tokenizer\n",
        "MAX_LEN = 100\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(source_df['combined'])\n",
        "\n",
        "def prepare_sequences(df):\n",
        "    sequences = tokenizer.texts_to_sequences(df['combined'])\n",
        "    padded = pad_sequences(sequences, padding='post', maxlen=MAX_LEN)\n",
        "    return torch.tensor(padded, dtype=torch.long), torch.tensor(df['label'].values, dtype=torch.long)\n",
        "\n",
        "X_source, y_source = prepare_sequences(source_df)\n",
        "X_target, y_target = prepare_sequences(target_df)\n",
        "\n",
        "# Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
        "\n",
        "source_loader = DataLoader(TextDataset(X_source, y_source), batch_size=32, shuffle=True)\n",
        "target_loader = DataLoader(TextDataset(X_target, y_target), batch_size=32, shuffle=True)\n",
        "\n",
        "# CNN model\n",
        "class CNNFeatureExtractor(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=100):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.conv = nn.Conv1d(embedding_dim, 128, kernel_size=5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x).squeeze(2)\n",
        "        return x\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, feature_extractor, output_dim):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.classifier = nn.Linear(128, output_dim)\n",
        "    def forward(self, x):\n",
        "        features = self.feature_extractor(x)\n",
        "        return self.classifier(features)\n",
        "\n",
        "# CORAL Loss\n",
        "class CORAL(nn.Module):\n",
        "    def forward(self, source, target):\n",
        "        d = source.size(1)\n",
        "        source_c = self.covariance(source)\n",
        "        target_c = self.covariance(target)\n",
        "        loss = torch.mean((source_c - target_c) ** 2)\n",
        "        return loss / (4 * d * d)\n",
        "\n",
        "    def covariance(self, x):\n",
        "        n = x.size(0)\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        xc = x - mean\n",
        "        cov = (xc.t() @ xc) / (n - 1)\n",
        "        return cov\n",
        "\n",
        "# Train CORAL CNN\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(np.concatenate([y_source.numpy(), y_target.numpy()]))\n",
        "y_source = label_encoder.transform(y_source.numpy())\n",
        "y_target = label_encoder.transform(y_target.numpy())\n",
        "\n",
        "y_source = torch.tensor(y_source, dtype=torch.long)\n",
        "y_target = torch.tensor(y_target, dtype=torch.long)\n",
        "y_all = np.concatenate([y_source.numpy(), y_target.numpy()])\n",
        "\n",
        "# Fix: use all classes for weight computation, fallback to uniform weights if mismatch\n",
        "all_classes = np.unique(y_all)\n",
        "present_classes = np.unique(y_source.numpy())\n",
        "if len(all_classes) == len(present_classes):\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=all_classes, y=y_source.numpy())\n",
        "else:\n",
        "    print(\"Mismatch in classes for weight computation. Falling back to uniform weights.\")\n",
        "    class_weights = np.ones(len(all_classes))\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "feature_extractor = CNNFeatureExtractor(VOCAB_SIZE)\n",
        "model = CNNClassifier(feature_extractor, output_dim=len(label_encoder.classes_))\n",
        "coral = CORAL()\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "patience = 3\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_classification = 0\n",
        "    for (xs, ys), (xt, _) in zip(source_loader, target_loader):\n",
        "        optimizer.zero_grad()\n",
        "        source_feat = feature_extractor(xs)\n",
        "        target_feat = feature_extractor(xt)\n",
        "        cls_output = model(xs)\n",
        "        cls_loss = criterion(cls_output, ys)\n",
        "        coral_loss = coral(source_feat, target_feat)\n",
        "        loss = cls_loss + coral_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_classification += cls_loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(source_loader)\n",
        "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Classification Loss: {total_classification / len(source_loader):.4f}\")\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# Evaluate on full combined test set\n",
        "model.eval()\n",
        "X_combined = torch.cat([X_source, X_target])\n",
        "y_combined = torch.cat([y_source, y_target])\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_combined)\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "print(\"\\n=== Evaluation on Combined Dataset ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_combined, preds))\n",
        "print(classification_report(y_combined, preds, target_names=label_encoder.classes_.astype(str)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZyaLcQGDpfH",
        "outputId": "111de380-6ae3-47b9-ab6a-7f37fecd2fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mismatch in classes for weight computation. Falling back to uniform weights.\n",
            "Epoch 1 | Loss: 0.2718 | Classification Loss: 0.2718\n",
            "Epoch 2 | Loss: 0.1483 | Classification Loss: 0.1483\n",
            "Epoch 3 | Loss: 0.1128 | Classification Loss: 0.1128\n",
            "Epoch 4 | Loss: 0.0874 | Classification Loss: 0.0874\n",
            "Epoch 5 | Loss: 0.0621 | Classification Loss: 0.0621\n",
            "Epoch 6 | Loss: 0.0483 | Classification Loss: 0.0483\n",
            "Epoch 7 | Loss: 0.0358 | Classification Loss: 0.0358\n",
            "Epoch 8 | Loss: 0.0269 | Classification Loss: 0.0269\n",
            "Epoch 9 | Loss: 0.0204 | Classification Loss: 0.0204\n",
            "Epoch 10 | Loss: 0.0161 | Classification Loss: 0.0161\n",
            "Epoch 11 | Loss: 0.0107 | Classification Loss: 0.0107\n",
            "Epoch 12 | Loss: 0.0088 | Classification Loss: 0.0088\n",
            "Epoch 13 | Loss: 0.0075 | Classification Loss: 0.0075\n",
            "Epoch 14 | Loss: 0.0052 | Classification Loss: 0.0052\n",
            "Epoch 15 | Loss: 0.0052 | Classification Loss: 0.0052\n",
            "Epoch 16 | Loss: 0.0039 | Classification Loss: 0.0039\n",
            "Epoch 17 | Loss: 0.0033 | Classification Loss: 0.0033\n",
            "Epoch 18 | Loss: 0.0028 | Classification Loss: 0.0028\n",
            "Epoch 19 | Loss: 0.0028 | Classification Loss: 0.0028\n",
            "Epoch 20 | Loss: 0.0022 | Classification Loss: 0.0022\n",
            "\n",
            "=== Evaluation on Combined Dataset ===\n",
            "Accuracy: 0.8353831598864712\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.87      0.90      2236\n",
            "           1       0.65      0.89      0.75       775\n",
            "           2       0.00      0.00      0.00       160\n",
            "\n",
            "    accuracy                           0.84      3171\n",
            "   macro avg       0.53      0.59      0.55      3171\n",
            "weighted avg       0.81      0.84      0.82      3171\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}