{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsnT1ghr4E4o",
        "outputId": "e80fa68e-d240-4fc1-ac3d-c2a8d27b463f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "captum 0.8.0 requires numpy<2.0, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers transformers-interpret torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvdxAnT-3Hbm",
        "outputId": "e2d690e4-7966-4abb-ccd6-30ca5ff723f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: transformers-interpret in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: captum>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers-interpret) (0.8.0)\n",
            "Requirement already satisfied: ipython<8.0.0,>=7.31.1 in /usr/local/lib/python3.11/dist-packages (from transformers-interpret) (7.34.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum>=0.3.1->transformers-interpret) (3.10.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<8.0.0,>=7.31.1->transformers-interpret) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.31.1->transformers-interpret) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum>=0.3.1->transformers-interpret) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum>=0.3.1->transformers-interpret) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHpPnUun5xNx",
        "outputId": "f2099b83-fc04-43da-89b3-c4be0cb99532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJa6H3Fy3C55",
        "outputId": "9d953f76-ff98-4cfb-a9be-dea8b74318cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Text: Metformin is used to help control diabetes, but it does not cure it.\n",
            "ğŸ“Œ Important Tokens: [('control', 0.051416024565696716), ('diabetes', 0.07729330658912659)]\n",
            "ğŸ“Š Threshold: 0.0422\n"
          ]
        }
      ],
      "source": [
        "# Import necessary modules\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers_interpret import SequenceClassificationExplainer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/new_model/\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True)\n",
        "model.eval()\n",
        "\n",
        "# Create explainer\n",
        "explainer = SequenceClassificationExplainer(model, tokenizer)\n",
        "\n",
        "# Sample text input\n",
        "text = \"Metformin is used to help control diabetes, but it does not cure it.\"\n",
        "attributions = explainer(text)\n",
        "\n",
        "# Merge subwords and aggregate scores\n",
        "merged_tokens = []\n",
        "merged_scores = []\n",
        "current_token = \"\"\n",
        "current_score = 0.0\n",
        "\n",
        "for token, score in attributions:\n",
        "    if token.startswith(\"##\"):\n",
        "        current_token += token[2:]\n",
        "        current_score += score\n",
        "    else:\n",
        "        if current_token:\n",
        "            merged_tokens.append(current_token)\n",
        "            merged_scores.append(current_score)\n",
        "        current_token = token\n",
        "        current_score = score\n",
        "\n",
        "# Add last token\n",
        "if current_token:\n",
        "    merged_tokens.append(current_token)\n",
        "    merged_scores.append(current_score)\n",
        "\n",
        "# Filter to positive scores\n",
        "positive_scores = [s for s in merged_scores if s > 0]\n",
        "mean_score = np.mean(positive_scores) if positive_scores else 0\n",
        "std_score = np.std(positive_scores) if positive_scores else 0\n",
        "threshold = mean_score + 0.5 * std_score\n",
        "\n",
        "# Get tokens above threshold\n",
        "important_tokens = [\n",
        "    (token, score) for token, score in zip(merged_tokens, merged_scores) if score > threshold\n",
        "]\n",
        "\n",
        "# Fallback: If no tokens pass, show top 2 tokens with highest positive scores\n",
        "if not important_tokens:\n",
        "    sorted_tokens = sorted(\n",
        "        [(token, score) for token, score in zip(merged_tokens, merged_scores) if score > 0],\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )\n",
        "    important_tokens = sorted_tokens[:2]\n",
        "\n",
        "# Display results\n",
        "print(\"Text:\", text)\n",
        "print(\"Important Tokens:\", important_tokens)\n",
        "print(\"Threshold:\", round(threshold, 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers_interpret import SequenceClassificationExplainer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_path = \"/content/drive/MyDrive/new_model/\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True)\n",
        "model.eval()\n",
        "\n",
        "# Create explainer\n",
        "explainer = SequenceClassificationExplainer(model, tokenizer)\n",
        "\n",
        "# List of 5 test sentences\n",
        "test_sentences = [\n",
        "    \"Insulin can reverse diabetes permanently.\",\n",
        "    \"Drinking bitter leaf tea cures diabetes overnight.\",\n",
        "    \"Regular exercise helps manage blood sugar levels effectively.\",\n",
        "    \"Using herbal supplements alone can replace diabetes medication.\",\n",
        "    \"Metformin improves insulin sensitivity but is not a permanent solution.\"\n",
        "]\n",
        "\n",
        "# Function to process and extract important tokens\n",
        "def get_important_tokens(text):\n",
        "    attributions = explainer(text)\n",
        "\n",
        "    # Merge subwords\n",
        "    merged_tokens = []\n",
        "    merged_scores = []\n",
        "    current_token = \"\"\n",
        "    current_score = 0.0\n",
        "\n",
        "    for token, score in attributions:\n",
        "        if token.startswith(\"##\"):\n",
        "            current_token += token[2:]\n",
        "            current_score += score\n",
        "        else:\n",
        "            if current_token:\n",
        "                merged_tokens.append(current_token)\n",
        "                merged_scores.append(current_score)\n",
        "            current_token = token\n",
        "            current_score = score\n",
        "\n",
        "    if current_token:\n",
        "        merged_tokens.append(current_token)\n",
        "        merged_scores.append(current_score)\n",
        "\n",
        "    # Filter to positive scores\n",
        "    positive_scores = [s for s in merged_scores if s > 0]\n",
        "    mean_score = np.mean(positive_scores) if positive_scores else 0\n",
        "    std_score = np.std(positive_scores) if positive_scores else 0\n",
        "    threshold = mean_score + 0.5 * std_score\n",
        "\n",
        "    # Get tokens above threshold\n",
        "    important_tokens = [\n",
        "        (token, score) for token, score in zip(merged_tokens, merged_scores) if score > threshold\n",
        "    ]\n",
        "\n",
        "    # Fallback: top 2 if none pass\n",
        "    if not important_tokens:\n",
        "        sorted_tokens = sorted(\n",
        "            [(token, score) for token, score in zip(merged_tokens, merged_scores) if score > 0],\n",
        "            key=lambda x: x[1],\n",
        "            reverse=True\n",
        "        )\n",
        "        important_tokens = sorted_tokens[:2]\n",
        "\n",
        "    return important_tokens, threshold\n",
        "\n",
        "# Run and print results\n",
        "for text in test_sentences:\n",
        "    important_tokens, threshold = get_important_tokens(text)\n",
        "    print(f\" Text: {text}\")\n",
        "    print(f\"Important Tokens: {important_tokens}\")\n",
        "    print(f\"Threshold: {round(threshold, 4)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rqw4g7Q-d3Z",
        "outputId": "007f68b1-82bf-4d27-a26c-8aaf2c4b80f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“ Text: Insulin can reverse diabetes permanently.\n",
            "ğŸ“Œ Important Tokens: [('diabetes', 0.07572530955076218)]\n",
            "ğŸ“Š Threshold: 0.0707\n",
            "\n",
            "ğŸ“ Text: Drinking bitter leaf tea cures diabetes overnight.\n",
            "ğŸ“Œ Important Tokens: [('cures', 0.3244030438363552), ('diabetes', 0.34785395860671997)]\n",
            "ğŸ“Š Threshold: 0.2373\n",
            "\n",
            "ğŸ“ Text: Regular exercise helps manage blood sugar levels effectively.\n",
            "ğŸ“Œ Important Tokens: [('blood', 0.8433975577354431)]\n",
            "ğŸ“Š Threshold: 0.3819\n",
            "\n",
            "ğŸ“ Text: Using herbal supplements alone can replace diabetes medication.\n",
            "ğŸ“Œ Important Tokens: [('diabetes', 0.2604775130748749)]\n",
            "ğŸ“Š Threshold: 0.2605\n",
            "\n",
            "ğŸ“ Text: Metformin improves insulin sensitivity but is not a permanent solution.\n",
            "ğŸ“Œ Important Tokens: [('.', 0.06704144924879074)]\n",
            "ğŸ“Š Threshold: 0.0536\n"
          ]
        }
      ]
    }
  ]
}